---
title: "Predicting Yelp Ratings Using Multilevel Ordinal Regression"
author: "Albert Ding"
date: "December 2018"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, comment=NA)
```

## Abstract
Yelp is the leading provider of online business reviews crowdsourced as user generated content. When consumers are contemplating purchasing decisions, Yelp can heavily influence the buyer's final decision. The impact of these ratings, scored from one to five stars, is especially pronounced within the restaurant industry, where 40% of the company's 170 million reviews are focused.

Given this phenomenon, I leveraged the restaurant ratings of Yelp to examine what factors influence the rating from an individual review. I explored several hypotheses and estimated the relationship between ratings and several independent variables using linear regression, ordinal multinomial regression, and multilevel linear and ordinal multinomial regression. 

The onus of conducting a multilevel model arose from my discovery that ratings of the same business are significantly clustered. Based on the model estimates, I presented evidence that restaurants in the second price category, or two dollar signs on Yelp, have lower ratings, and reviews written by on average more satisfied users tend to be more positive, the strongest observed relationship of all my analysis. The results suggest that restaurant management and patrons alike should pay attention to features other than descriptions and pictures of food on Yelp and should consider who is writing the review before giving it weight.  Given the limited findings, a plethora of topics remain to be explored linking the relationship between restaurant rating and information on reviewer demographic and other restaurant features. 

## Introduction
Since its founding in 2004, Yelp has aimed to provide a digital form for word-of-mouth recommendations. Replicating the positive / negative sentiment of business reviews, Yelp requires a rating from one to five in one star increments for each review. These ratings are then averaged in aggregate for restaurants and shown in half star increments.

Given the popularity and mindshare of Yelp among consumers and restaurants, these ratings leave a strong impression. Yelp boasts over 173 million monthly active users as of Q3 2018, and among consumers, Yelp, Facebook, and Google are the most trusted review sites according to Uberall, a location marketing software company. (1)  

Restaurants are keenly aware of these facts; among small and medium size businesses, Yelp ranks as the fourth most popular channel for online advertising with 22% paying in one form or another. A frequently-cited paper written by Professor Michael Luca of Harvard Business School even proposes a causal inference on sales in proclaiming, "a one-star increase in Yelp rating leads to a 5-9 percent increase in revenue." The implications of Yelp ratings on both consumer perception and business results cannot be understated. (2) (3) 

In exploring the nuances of reviewer ratings, this project sheds light on how reviewer satisfaction differs. These learnings may prove helpful to anyone reading a restaurant description or review and wondering how to interpret them. 

## Method
Using data from the twelfth annual Yelp Academic Challenge, I explored several hypotheses about restaurant experiences.  I chose this dataset because Yelp is the largest source of restaurant reviews worldwide, and their publicly available data are likely the most representative of American restaurant reviews available, especially considering 90% of Yelp's user base lives in the US. 

I first explored several potential factors contributing to positive restaurant ratings through univariate and correlational analyses.  Next, I predicted reviewer satisfaction as a function of several explanatory variables using linear regression.  I noticed that my results were mismatched because I was modeling an ordinal response as a continuous outcome. Nevertheless, I referenced the linear model throughout this paper and preserved its results in the appendix.  

I then predicted ratings as a five-category ordinal response using ordinal multinomial regression, which agreed directionally with the linear models.  Finally, I show that there is substantial clustering of rating scores within reviews of the same restaurant, indicating that multilevel models are more appropriate than single level ones. Based on this finding, I predicted satisfaction as a multilevel ordinal regression allowing varying intercepts within groupings for the same business. In the appendix, I have also followed through with a multilevel linear model for comparative purposes.

## Data
To do this analysis, I first parsed the JSON files publicly available at www.yelp.com/dataset using base R and the jsonlite packages. After including only restaurants, removing missing values, and excluding businesses with less than 10 reviews, I narrowed the dataset down to 180,000 reviews or so. From there, I took a random subset of 10,000 reviews to improve computation speed.  

I created independent variables for the years the reviewer has been writing on Yelp, his or her average rating conferred in the past, and the length of the review. On the side of restaurants, I generated independent variables from the price category of the restaurant, whether the restaurant has TVs, and whether the restaurant is open 24 hours a day. Finally, I converted variables to their appropriate types, such as converting the ratings to categorical for the ordinal logistic regression and centering and scaling the continuous predictors by subtracting their mean and dividing by one standard deviation. Although the interpretability of the continuous predictors were diminished along the way, their effect size became more directly comparable. 

I decided to put my analysis of the relationship between review word count and rating into the appendix.  I found that there was a generally negative relationship, as longer reviews tend to be less positive, but I decided not to include this feature in the regression analysis. My reasoning is that word count is more of a consequence of restaurant experience than anything about the restaurant or the reviewers themselves.


```{r results='hide', message=F, warning=F, include=F}
# Clear the memory
rm(list = ls())

#install.packages("...")

library(lme4)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(stringr)
library(psych)
library(reshape2)
library(nnet)
library(data.table)
library(ordinal)
library(PResiduals)
library(gridExtra)
library(MASS)
library(sure)
library(texreg)
library(arm)
library(coefplot)
library(scales)
library(kableExtra)
library(ggrepel)
library(reshape2)
library(gridExtra)
library(cpgen)
library(arm)

businesses_infile <- '../data/yelp_academic_dataset_business.json'
users_infile <- '../data/yelp_academic_dataset_user_small.json'
reviews_infile <- '../data/yelp_academic_dataset_review_small.json'
```

```{r results='hide', message=F, warning=F, include=F}
read_json <- function(infile) {
  txt <- readChar(infile, file.info(infile)$size)
  # Add a comma at the end of each line
  txt <- gsub("\\n", "\n,", txt)
  # Remove the last comma
  txt <- substr(txt, 1, nchar(txt) - 1)
  # Add brackets around the dictionaries to make it JSON
  txt <- paste0("[", txt, "]")
  # Read the JSON into a data frame
  return(fromJSON(txt))
}

# This takes a few minutes to run
businesses <- read_json(businesses_infile)
mean(is.na(businesses[, "attributes"][, "RestaurantsPriceRange2"]))
sum(is.na(businesses[, "attributes"][, "RestaurantsPriceRange2"]))

# Get a few columns from within the "attributes" column
businesses$RestaurantsPriceRange2 <- businesses[, "attributes"][, "RestaurantsPriceRange2"]
businesses$HasTV <- businesses[, "attributes"][, "HasTV"]
businesses$Open24Hours <- businesses[, "attributes"][, "Open24Hours"]

# Only keep restaurants with price data
dim(businesses)
businesses <- businesses[!is.na(businesses$RestaurantsPriceRange2), ]
businesses <- businesses[businesses$categories %like% "Restaurants", ]
dim(businesses)

reviews <- read_json(reviews_infile)
users <- read_json(users_infile)

# Merge the datasets while keeping names clear
# All columns are about reviews or labeled as _business or _user
names(businesses) = gsub("$", "_business", names(businesses))
businesses = rename(businesses, business_id=business_id_business)
names(users) = gsub("$", "_user", names(users))
users = rename(users, user_id=user_id_user)
df = merge(reviews, businesses, by="business_id", all=F, suffixes=c("", "_business"))
df = merge(df, users, by="user_id", all=F, suffixes=c("", "_user"))
dim(df)
names(df)

# Free up memory
rm(businesses)
rm(reviews)
rm(users)

## Create some useful variables
# Parse text to get features
df$word_count <- str_count(df$text,'\\w+')

# How many years the user has been yelping for
get_yelping_years <- function(date_str) {
  date <- as.Date(date_str)
  today <- as.Date("2018-11-29")
  years <- as.integer(floor((today - date) / 365))
  return(years)
}
df$yelping_years_user <- sapply(df$yelping_since_user, get_yelping_years)

# Make the $$ variable numeric
df$RestaurantsPriceRange2_business <- as.integer(df$RestaurantsPriceRange2_business)

# Make categorical outcome for mlogit
df$stars_cat <- relevel(as.factor(df$stars), ref<-"1")

df[is.na(df$Open24Hours_business), 'Open24Hours_business'] <- 'False'

cols <- c(
  "stars",
  "stars_cat",
  "yelping_years_user",
  "average_stars_user",
  "RestaurantsPriceRange2_business",
  "HasTV_business",
  "Open24Hours_business",
  "business_id",
  "word_count"
)
df <- df[, cols]
df <- na.omit(df)
```

```{r, include=F}
# Calculate this now before standardization
# Mean stars vs. num restaurant reviews scatterplot
business_df <- df %>%
  group_by(business_id) %>%
  summarise(
    mean_stars=mean(stars),
    review_count=n()
  )
# Only include businesses with at least 10 reviews
min_reviews <- 10
business_df <- business_df[business_df$review_count >= min_reviews,]
df <- merge(df, business_df[, c("business_id", "review_count")], by="business_id")
```

## Results

### Distribution of Review Stars
Looking at the distribution of review ratings, you can see that the majority of the 189,000 total restaurant reviews in the dataset prior to sampling are 4's and 5's.

```{r, echo = FALSE, warning=FALSE, results='hide',message=FALSE}
df2 <- df %>% group_by(stars) %>%
      summarise(total = n()) %>%
      mutate(prop=total/sum(total))

ggplot(data = df2) + 
    geom_bar(mapping = aes(x = factor(stars), y = total, 
        fill=factor(stars), labels=total, size=.3, show.legend = FALSE),stat="identity")+
    xlab("\n Ratings") +
    ylab("Count\n") +
    ggtitle("Distribution of Yelp Review Ratings in Total Dataset\n") +
    theme_classic() +
    theme(plot.title=element_text(hjust=0.5)) +
    theme(legend.position="none") +
    scale_y_continuous(label=comma)
    
```


### User's Average Review Stars
Reviews are strongly impacted by the author, as reviews by generally positive users are much more likely to be positive. Note that the size of the points below are proportional to sample size observed for each. 
```{r, echo=FALSE}
df$average_stars_user_cat <- cut(df$average_stars_user, breaks=seq(-1, 6, 0.4))
plot_data <- df %>%
  group_by(average_stars_user_cat) %>%
  summarise(
    mean_stars=mean(stars),
    review_count=n()
  )
plot_data <- na.omit(plot_data)
plot1 <- ggplot(
  plot_data,
  aes(
    x=average_stars_user_cat,
    y=mean_stars,
    size=review_count
  )) +
  geom_point() +
  geom_smooth(method="loess", se=F) + 
  xlab("\nMean User Rating for all Businesses") +
  ylab("Ratings Conferred to Restaurants in Dataset\n") +
  ggtitle("\nRestaurant Ratings of Users by Mean User Rating Bins") +
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5)) +
  theme(legend.position="none")

plot1
```

### Years Reviewer on Yelp Versus Ratings
There appears to be a weak relationship between years Yelping and ratings.
```{r, echo=FALSE}
plot_data <- df %>%
  group_by(yelping_years_user) %>%
  summarise(
    mean_stars=mean(stars),
    review_count=n()
  )
# Remove the 10 reviews from users with 0 or 14 years
plot_data <- plot_data[plot_data$yelping_years_user != 0,]
plot_data <- plot_data[plot_data$yelping_years_user != 14,]

plot2 <- ggplot(
  plot_data,
   aes(
     x=yelping_years_user,
     y=mean_stars,
     size=review_count
   )
 ) +
   geom_point() +
   xlab("Number of Years Review Has Been on Yelp") +
   ylab("Mean Rating") +
   ggtitle("Ratings by Users' Years on Yelp") +
   theme_classic() +
   theme(plot.title=element_text(hjust=0.5)) +
   theme(legend.position="none")
plot2
```


### Business Attributes

```{r, include=F}
df_TV <- df %>% 
  group_by(HasTV_business,stars) %>% 
  summarise(count=n()) %>% 
  mutate(perc=count/sum(count))

df_TV2 <- df_TV %>%
  mutate(weighted_rating=perc*stars) %>%
  group_by(HasTV_business) %>%
  mutate(avg=sum(weighted_rating))

         
brks <- c(0, 0.25, 0.5, 0.75, 1)

b1 <- ggplot(df_TV, aes(x = factor(HasTV_business), y = perc*100, fill = factor(stars)))  +
  geom_bar(stat="identity", width = 0.7) +
  labs(x = "\nHas TV?", y = "Percent", fill = "Rating") +
  scale_x_discrete(labels = c('No','Yes')) +     
  ggtitle("Ratings for Restaurants -\nwith TV and Not\n") +
  theme(plot.title = element_text(hjust = 0.5)) 
             
df_open <- df %>% 
  group_by(Open24Hours_business,stars) %>% 
  summarise(count=n()) %>% 
  mutate(perc=count/sum(count))

df_open2 <- df_open %>%
  mutate(weighted_rating=perc*stars) %>%
  group_by(Open24Hours_business) %>%
  mutate(avg=sum(weighted_rating))

b2 <- ggplot(df_open, aes(x = factor(Open24Hours_business), y = perc*100, fill = factor(stars)))  +
  geom_bar(stat="identity", width = 0.7) +
  labs(x = "\nOpen 24 Hours?", y = "Percent", fill = "Rating") +
  scale_x_discrete(labels = c('No','Yes')) +     
  ggtitle("Ratings for Restaurants -\nOpen 24 Hours and Not\n") +
  theme(plot.title = element_text(hjust = 0.5))

df_price <- df %>% 
  group_by(RestaurantsPriceRange2_business,stars) %>% 
  summarise(count=n()) %>% 
  mutate(perc=count/sum(count))

df_price2 <- df_price %>%
  mutate(weighted_rating=perc*stars) %>%
  group_by(RestaurantsPriceRange2_business) %>%
  mutate(avg=sum(weighted_rating))

b3 <- ggplot(df_price, aes(x = factor(RestaurantsPriceRange2_business), y = perc*100, fill = factor(stars)))  +
  geom_bar(stat="identity", width = 0.7) +
  labs(x = "\nPrice Range", y = "Percent", fill = "Rating") +     
  ggtitle("Ratings for Restaurants by\nPrice Category\n") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
      scale_x_discrete(labels = 
          c('Least Expensive','Less Expensive','More Expensive','Most Expensive'))

b4 <- ggplot(df, aes(factor(RestaurantsPriceRange2_business), 
                     factor(stars))) + 
      geom_jitter(alpha=0.1) + 
      scale_x_discrete(labels = 
          c('Least Expensive','Less Expensive','More Expensive','Most Expensive')) +     
      ggtitle("Ratings for Restaurants by\nPrice Category\n") +
      labs(x = "\nPrice Range", y = "Ratings\n", fill = "Rating") +
      theme(plot.title = element_text(hjust = 0.5)) + 
      theme(axis.text.x = element_text(angle = 45, hjust = 1))

b5 <- ggplot(df, aes(factor(Open24Hours_business), factor(stars))) + 
      geom_jitter(alpha=0.1) +     
      ggtitle("Ratings for Restaurants - \nOpen 24 Hours and Not") +
      labs(x = "\nOpen 24 Hours?", y = "Ratings\n", fill = "Rating") +
      theme(plot.title = element_text(hjust = 0.5)) +
      scale_x_discrete(labels = c('No','Yes'))

b6 <- ggplot(df, aes(factor(HasTV_business), factor(stars))) + 
      geom_jitter(alpha=0.05) +
      scale_x_discrete(labels = c('No','Yes')) +     
      ggtitle("Ratings for Restaurants - \nwith TV and Not") +
      labs(x = "\nHas TV?", y = "Ratings\n", fill = "Rating") +
      theme(plot.title = element_text(hjust = 0.5)) +
      scale_x_discrete(labels = c('No','Yes'))

```

Although they don't diverge significantly, restaurants without a TV appear to have receive four or five ratings more frequently than restaurants with at least one TV. There is a large sample size in every category making our jitter plot uninterpretable even at very low alpha levels.  
```{r, echo=FALSE}
grid.arrange(b1,b6,nrow=1)
```

Businesses open 24 hours have slightly more negative reviews. After running the model and seeing such a large standard error for a predictor term based on 24 hour access, I revisited the jitter plot and realized that there are is much smaller sample size for restaurants open 24 hours. I keep this predictor in the model nonetheless while acknowledging its limitations in terms of comparative and predictive value.  
```{r, echo=FALSE}
grid.arrange(b2,b5,nrow=1)
```

Looking at price cateogires in ascending orders, you can see that restaurants in the lowest price category tend to have the highest proportion of four and five star ratings. After that the proportions vary.

```{r, echo=FALSE}
grid.arrange(b3,b4,nrow=1)
```


### Correlation matrix
Several factors are highly correlated with the rating of an individual review.  In particular, longer reviews tend to be more negative, while reviews written by users who write more positive reviews on average tend to be more positive.  Reviews of more expensive restaurants are slightly more negative than reviews of cheaper restaurants.

```{r, echo=FALSE}
cols <- c(
  "stars",
  "average_stars_user",
  "yelping_years_user",
  "word_count",
  "RestaurantsPriceRange2_business"
)
corr_df <- df[, cols]
# Only keep numeric columns
numeric_cols <- sapply(corr_df, is.numeric)
corr_df <- corr_df[, numeric_cols]
corr_df <- na.omit(corr_df)
cormat <- round(cor(corr_df), 2)
diag(cormat) <- NA
# Get upper triangle of the correlation matrix
cormat[lower.tri(cormat)] <- NA
melted_cormat <- melt(cormat, na.rm=T)
# Heatmap
plot3 <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value)) +
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
  coord_fixed() + ggtitle("Correlation Matrix\n") +
  labs(x = "\nVariable One", y = "Variable Two\n") +
  scale_x_discrete(labels = c("Average Rating of User","Years User on Yelp","Word Count of Review","Price Range")) +
  scale_y_discrete(labels = c("Rating of Review","Average Rating of User","Years User on Yelp","Word Count of Review"))
plot3  
```

```{r, include=F}
# Standardize the independent variables
ivs <- c(
  "yelping_years_user",
  "average_stars_user"
)

for (iv in ivs) {
  iv_mean <- mean(df[, iv], na.rm = T)
  df[, iv] <- df[, iv] - iv_mean
  
  iv_sd <- sd(df[, iv], na.rm = T)
  df[, iv] <- df[, iv] / iv_sd
}

#Taking a random sample from our larger dataset 

n <- 10 * 1000
df <- sample_n(df, n)

length(unique(df$business_id))

```

### Model Summary - Single Level Ordinal Regression Model 
I consider review stars to be an ordinal variable and predict the increased probability of having 2-5 stars, compared to one star.  I find that the primary relationships found in the linear regression remain (as seen in appendix). Users with higher average stars are more likely to give higher ratings, and businesses in the second price category are more likely to receive lower ratings.  The strongest relationship with ratings is the users' average rating in previous reviews, as one standard deviation's increase in average review stars is associated with a 4 times (e ^ 1.4) increase in the odds of having one more star when compared to the mean average review stars. Please note that the two continuous variables, mean review stars and years user has been on Yelp, have been centered and scaled while the baseline for the categorical predictors are the lowest price category, no TV, and not open 24 hours a day. The output of the model is presented in graphical, table, and equation form with interpretation following.


```{r, include=F, warning=FALSE, results='hide',message=FALSE}
model1 <- polr(
  stars_cat ~ yelping_years_user + average_stars_user +
    factor(RestaurantsPriceRange2_business) + factor(HasTV_business) + factor(Open24Hours_business),
  data=df,
  Hess=T
)

plot4 <- coefplot(model1) +
  xlab('\nCoefficient predicting stars') +
  ylab('Independent variable\n') +
  ggtitle('Ordinal Logistic Regression Coefficients\n(95% interval)\n') +
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5)) 

```

```{r, echo=FALSE}
screenreg(model1, custom.model.names = "Single Level Ordinal Regression Model")
kable(round(confint(model1),2))
plot4
```

```{r, include=F}
summary(model1)
```

In equation form, our model has generated coefficients for each predictor effect on the cumulative log odds of a rating being a one to five star rating using four threshold points estimated as intercept values. For the probability that any given observation falls in the top and bottom categories, we estimate values by using equations one and four. For equation four we can simply take an inverse-logit of the value on the right side of the equation, while for equation one we can do the same and subtract from one. 

For two, three and four star ratings we must take probabilities in adjacent categories and subtract one from another. For example, the probability that a review has two stars can be deduced by taking the inverse logit from equation two, which tells us the probability that the rating is greater than two stars, and subtract the inverse logit from equation one, which tells us the probability that rating is greater than one star. For the sake of compact-ness, we have omitted writing three different indicator terms for price range but acknowledge that is a four level factor. 

Equation one:
$$log(\frac{\hat{\pi _{2}}+\hat{\pi _{3}}+\hat{\pi _{4}}+\hat{\pi _{5}}}{\hat{\pi _{1}}}) = - \alpha_{1|2} + \beta _{1}x_{user.years} + \beta _{2}x_{user.avgstar} + \beta _{3}x_{price.range} + \beta _{4}x_{TV} - \beta _{5}x_{open24}$$
Equation two:
$$log(\frac{\hat{\pi _{3}}+\hat{\pi _{4}}+\hat{\pi _{5}}}{\hat{\pi _{1}}+\hat{\pi _{2}}}) = - \alpha_{2|3} + \beta _{1}x_{user.years} + \beta _{2}x_{user.avgstar} + \beta _{3}x_{price.range} + \beta _{4}x_{TV} - \beta _{5}x_{open24}$$
Equation three:
$$log(\frac{\hat{\pi _{4}}+\hat{\pi _{5}}}{\hat{\pi _{1}}+\hat{\pi _{2}}+\hat{\pi _{3}}}) = - \alpha_{3|4} + \beta _{1}x_{user.years} + \beta _{2}x_{user.avgstar} + \beta _{3}x_{price.range} + \beta _{4}x_{TV} - \beta _{5}x_{open24}$$
Equation four:
$$log(\frac{\hat{\pi _{5}}}{\hat{\pi _{1}}+\hat{\pi _{2}}+\hat{\pi _{3}}+\hat{\pi _{4}}}) = - \alpha_{4|5} + \beta _{1}x_{user.years} + \beta _{2}x_{user.avgstar} + \beta _{3}x_{price.range} + \beta _{4}x_{TV} - \beta _{5}x_{open24}$$

## Model visualization - Single Level Ordinal Regression Model
Visualizing the outcome, we plot the predicted probabilities of any given rating against a continuous scale for each continuous predictor, which has already been centered and scaled: the number of years the user has been using Yelp and the average rating the user has conferred overall. 

We see a somewhat muddled result for years the user has been using Yelp, but a very clear trend for the user's average rating. The higher the user's average ratings in the past, the higher the probability of giving higher restaurant ratings on any given review.   

```{r, echo=FALSE, warning=FALSE, results='hide',message=FALSE}
Newdata.df <- df
Newdata.df$yelping_years_user <- seq(-2,2, length.out = nrow(Newdata.df))
pred.df <- predict(model1, type = "probs", newdata = Newdata.df)
colnames(pred.df) <- c("1 Star","2 Star", "3 Star", "4 Star", "5 Star")

melt.prob <- reshape2::melt(data.frame(pred.df, yelping_years_user=Newdata.df$yelping_years_user), id.vars = "yelping_years_user",
                  variable.name = "outcome_category", value.name = "prob")
ggplot(melt.prob) + aes(x=yelping_years_user, y=prob, fill=factor(outcome_category) ) + 
  geom_bar(stat = "identity") +
  labs(x = "\nYears User on Yelp - Centered and Scaled", y = "Estimated Probability\n", fill = "Rating") +
  scale_fill_discrete(labels = c('1','2','3','4','5')) +
  ggtitle("Estimated Probability of a Rating\nConditioned on Years User on Yelp") +
  theme(plot.title = element_text(hjust = 0.5))


Newdata.df2 <- df
Newdata.df2$average_stars_user <- seq(-2,2, length.out = nrow(Newdata.df2))
pred.df2 <- predict(model1, type = "probs", newdata = Newdata.df2)
colnames(pred.df2) <- c("1 Star","2 Star", "3 Star", "4 Star", "5 Star")

melt.prob2 <- reshape2::melt(data.frame(pred.df2, average_stars_user=Newdata.df2$average_stars_user), id.vars = "average_stars_user",
                  variable.name = "outcome_category", value.name = "prob")
ggplot(melt.prob2) + aes(x=average_stars_user, y=prob, fill=factor(outcome_category) ) + 
  geom_bar(stat = "identity")  +
  labs(x = "\nMean Rating Conferred by User - Centered and Scaled", y = "Estimated Probability\n", fill = "Rating") +
  scale_fill_discrete(labels = c('1','2','3','4','5')) +
  ggtitle("Estimated Probability of a Rating\nConditioned on Mean Rating Conferred by User") +
  theme(plot.title = element_text(hjust = 0.5))
```

Next, I visualize the categorical predictors and expected probabilities holding the two continuous predictors contstant at our centered mean of zero. Our faceted plot grid shows the probabilities within each category for businesses with and without TV within each plot, with and without 24 hour service along the rows, and for price categories along the columns. 

You can see roughly that probabilities of higher ratings are  greater for businesses without TVs and for businesses without 24 hour service, by comparing top row with bottom row, while acknowledging differences in sample size. Moreover, you see that there is a less clear trend from lowest price category to highest price category, but we see that price category two has the lowest proportions of four and five ratings regardless of any other factors. This seems to directionally agree with out model determining statistical significance of price category two. We keep in mind the miniscule sample size of the 24 hours open restaurants in discounting these results. 

```{r, echo=FALSE, warning=FALSE, results='hide',message=FALSE}
predx<- expand.grid(HasTV_business=c("True","False"),Open24Hours_business=c("True","False"),RestaurantsPriceRange2_business=c("1","2","3","4"),average_stars_user=(0),yelping_years_user=(0))
predy<-predict(model1,newdata=predx,type = "p")

melt10<-melt(cbind(predx,predy)) %>%
      filter(value > 0.01, value < 1)

facetnames24hours <- list(
  'True'="Open 24 hours",
  'False'="Not Open 24 hours"
)

facetnamespricerange <- list(
  '1'="Least Expensive",
  '2'="Less Expensive",
  '3'="More Expensive",
  '4'="Most Expensive"
)

facet_labeller1 <- function(variable,value){
  return(facetnames24hours[value])
}

facet_labeller2 <- function(variable,value){
  return(facetnamespricerange[value])
}

ggplot(melt10,id.vars = c("HasTV_business","Open24Hours_business"))+
  geom_bar(stat="identity")+aes(x=HasTV_business,y=value, fill=variable) +
  facet_grid(Open24Hours_business~RestaurantsPriceRange2_business, labeller = labeller(Open24Hours_business = facet_labeller1, RestaurantsPriceRange2_business = facet_labeller2)) +
  geom_text(aes(label = round(value,2)),size = 3, position = position_stack(vjust = 0.5)) +
  scale_x_discrete(labels = c('Yes','No'))+
  labs(x = "\nHas TV?", y = "Estimated Probability\n", fill = "Rating")


```

### Model Check - Single Level Ordinal Regression Model
Next, I look at a series of residual plots of predictions for each response category. The residuals look reasonable although there appears to be some trend and heteroscedacity; the residuals lie within +/- 0.6 standard units. The binned points are mostly within the two standard error line which may be overconfident. For the five star rating in particular, the binned residuals are a bit more problematic. Here, almost all of the residuals are positive, indicating that the model has underestimated the expected probabilities.

```{r, echo=FALSE, warning=FALSE, results='hide',message=FALSE}
predx2<- expand.grid(HasTV_business=c("True","False"),Open24Hours_business=c("True","False"),RestaurantsPriceRange2_business=c("1","2","3","4"),average_stars_user=(-2:2),yelping_years_user=(-2:2))

predy2<-predict(model1,newdata=predx2,type = "p")

residr<-dcast(df,HasTV_business +Open24Hours_business+RestaurantsPriceRange2_business+average_stars_user+yelping_years_user~stars_cat)[,6:10]-predy2

par(mfrow=c(2,3))
binnedplot(predy2[,1],residr[,1], main= paste("Binned Residuals for One Rating"))
binnedplot(predy2[,2],residr[,2], main= paste("Binned Residuals for Two Rating"))
binnedplot(predy2[,3],residr[,3], main= paste("Binned Residuals for Three Rating"))
binnedplot(predy2[,4],residr[,4], main= paste("Binned Residuals for Four Rating"))
binnedplot(predy2[,5],residr[,5], main= paste("Binned Residuals for Five Rating"))
```

This method of examining multiple residuals corresponding to the ordinal outcomes makes interpretation of this diagnostic tool more challenging. Building off the research of Li and Shepherd (2012), I try using sign-based statistic (SBS), or probabiliy-scale residuals. These residuals are inherently discrete and  sometimes display unusual patterns in the diagnostic plots. Li and Shepherd show that the sign-based-statistic (SBS) can be used as a residual for ordinal outcomes. (4) (5)

For an ordinal outcome Y:
$$R_{SBS} = E(sign(y-Y)) = Pr(y>Y) - Pr(y < Y)$$

I plot the probability-scale residuals against two continuous predictors and find that they are unrelated to the years a user has been Yelping, and somewhat related to users' average review stars. 

The Q-Q plot indicates that the model looks ok.
```{r, echo=F, warning=FALSE, results='hide',message=FALSE}

# Obtain the SBS/probability-scale residuals
pres <- presid(model1)

plot5 <- ggplot(data.frame(x = df$yelping_years_user, y = pres), aes(x, y)) +
  geom_point(color = "#444444", shape = 19, size = 2, alpha = 0.5) +
  geom_smooth(color = "red", se = FALSE) +
  ylab("Probability-scale residual") +
  xlab("Years user has Yelped")
plot6 <- ggplot(data.frame(x = df$average_stars_user, y = pres), aes(x, y)) +
  geom_point(color = "#444444", shape = 19, size = 2, alpha = 0.5) +
  geom_smooth(color = "red", se = FALSE) +
  ylab("Probability-scale residual") +
  xlab("User's Average Review Stars")
plot7 <- ggplot(data.frame(y = pres), aes(sample = y)) +
  stat_qq(distribution = qunif, dparams = list(min = -1, max = 1), alpha = 0.5) +
  xlab("Sample quantile") +
  ylab("Theoretical quantile")
grid.arrange(plot5, plot6, plot7, ncol=3)
```

Next, we plot the surrogate residuals which are defined as 

$$R_{S} = S - E(S|X)$$
where S is a continuous variable based on the conditional distribution of the latent variable Z given Y.  If Y = y, Liu and Zhang (2017) show that S follows a truncated distribution obtained by truncating the distribution of:
$$Z = -f(X,\beta)$$
using the distribution of:
$$(\alpha_{y-1},\alpha_{y})$$
While acknowledging an incomplete appreciation of the theory's full implications, I leverage a some of the key takeaways that are shown to be true if the model is correct:

1) symmetry around zero 
$$E(R_{S}|X)=0$$
2) homogeneity 
$$Var (R_{S}|X) = c$$
a constant that is independent of X. (6)

This appears to be mostly satisfied in the plots below, but I note that using this diagnostic, the QQ plot deviates a bit on extreme values of the theoretical quantiles indicating that the model may exhibit heavy tails.

```{r, echo=FALSE, warning=FALSE, results='hide',message=FALSE}
# Obtain surrogate residuals
sres <- resids(model1)
# Residual-vs-covariate plot and Q-Q plot
plot8 <- autoplot(sres, what = "covariate", x = df$yelping_years_user, xlab = "Years user has Yelped")
plot9 <- autoplot(sres, what = "covariate", x = df$average_stars_user, xlab = "User's Average Review Stars")
plot10 <- autoplot(sres, what = "qq", distribution = qnorm)
grid.arrange(plot8, plot9, plot10, ncol = 3)
```

### Intraclass correlation coefficient (ICC)
The intraclass correlation coefficient (ICC) is the proportion of variance explained by which business the review is about, rather than the observation-level, which is individual reviews, or random unknown factors.  The ICC is quite large, indicating that review stars are highly clustered within businesses.  This suggests that wmultilevel model is appropriate to account for this clustering and to avoid overstating confidence about the relationships estimated. The ICC is calculated below as:
```{r, echo=FALSE}
model2 <- lmer(stars ~ (1 | business_id), data=df)

model4 = lm(
  stars ~ yelping_years_user + average_stars_user +
    factor(RestaurantsPriceRange2_business) + factor(HasTV_business) + factor(Open24Hours_business),
  data=df
)

model5 = lmer(
  stars ~ yelping_years_user + average_stars_user + 
    factor(RestaurantsPriceRange2_business) + factor(HasTV_business) + factor(Open24Hours_business) +
    (1 | business_id),
  data=df
)


v <- data.frame(summary(model2)$varcor)
business_id <- v$vcov[[1]]
residual <- v$vcov[[2]]
icc <- business_id / (business_id + residual)
round(icc,3)
```

The ICC shows that the review observations are not independent of each other, as reviews of the same business are related to one another.  For this reason, it is appropriate to fit a multilevel model that accounts for this clustering, while still allowing us to estimate the effect of business-level factors.

### Model Summary - Multi-Level Ordinal Regression Model

I fitted a multilevel ordinal logistic regression model with an intercept varying by business and found very similar relationships as the single-level ordinal logistic regression.  That is, the most predictive factor remains a user's previous review satisfaction, and restaurants with TVs and restaurants open 24-hours tend to have more negative reviews. This model was fitted using the most commonly discussed method I found from online research: the CLMM function from the R package Ordinal. (7) 

This model fits the data better than the single-level model, as the BIC is smaller for the multilevel model. Moreover, compared to the linear and multilevel linear model the BIC remains the lowest.
```{r, echo=FALSE, warning=FALSE, results='hide',message=FALSE}
model3 <- ordinal::clmm(
  stars_cat ~ yelping_years_user + average_stars_user + factor(RestaurantsPriceRange2_business) + factor(HasTV_business) + factor(Open24Hours_business) +
    (1 | business_id),
  data=df
)

plot11 <- coefplot(model3) +
  xlab('Coefficient predicting stars') +
  ylab('Independent variable') +
  ggtitle('Multilevel Ordinal Logistic Regression Coefficients') +
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5))

```

```{r, echo=FALSE}
screenreg(model3, custom.model.names = "Multi-Level Ordinal Regression Model")
kable(round(confint(model3),2))
plot11

Model<-c("Multilevel Ordinal Regression", "Single-level Ordinal Regression","Multilevel Linear Regression", "Single-level Linear Regression")
AIC <-round(AIC(model3, model1, model5, model4)[,2],0)
BIC <-round(BIC(model3, model1, model5, model4)[,2],0)

Model_comparison<-cbind(Model,AIC ,BIC )
kable(Model_comparison,format = 'markdown', padding=1L)

```

The output of the multilevel model is similar to the single level regression model except it allows the intercept to vary around its mean value. The model can be generalized as written below - I'll forgo listing and interpreting all four cumulative odds models given its redundance to the four equations written for the single level ordinal regression:

$$log(\frac{Pr(y_i>\pi_i)}{1-Pr(y_i>\pi_i)}) = \alpha_{j[i]} + \beta _{1}x_{user.years} + \beta _{2}x_{user.avgstar} + \beta _{3}x_{price.range} + \beta _{4}x_{TV} - \beta _{5}x_{open24}$$
$$\alpha_j \sim N(\mu_\alpha, \sigma^{2})$$

### Model Checks - Multi-Level Ordinal Regression Model
After extensive research, I omitted examination of residuals and model fit for the multilevel ordinal regression due to technical complications and the absence of clearly defined methods. For the CLMM package used to fit the multi-level ordinal regression, there is not even a compatible predict function. The author of the "Ordinal" package, Rune Christensen, then known as Rune Haubo, commented in response to how to obtain residuals: 

"You are not alone in being surprised of the absence of residuals... And I would be delighted to implement residuals for CLMs and CLMMs in ordinal, its only that I have never seen a relevant definition of such residuals or been able to come up with one myself... There is at present no predict method for clmm objects, so here you have another challenge. However, as I indicated above, the real challenge is to figure out what to do with such residuals."

Ben Bolker, a frequently cited expert on mixed effect models, noted on the same thread:

"My first thought is that since fitted(model) works, you might be able to used fitted(model)-observed, but on second thought, you're going to have to figure out what scale the 'fitted' value is on and how it relates to the predicted value of the response."

Given the weight of expert opinion and after an exhaustive search, I conceded that there might not exist a pre-packaged method to apply the same types of analysis and functions to check this model. Nevertheless, the logic stands that a mixed effect model should fit at least as well as the single-level model fit given the intraclass correlations within the same business. This assertion is also reinforced by the fact that the mixed effects model had a lower BIC, even though BIC is relatively conservative and penalizes model complexity more heavily relative than AIC.

### Discussion
Both the ordinal regression models agree about the relationships between the factors examined and a positive restaurant experience.  In particular, they suggest that restaurants in the second price category (two dollar signs on Yelp) tend to be more negative, while reviews written by Yelpers who usually write positive reviews are much more likely to be positive and those by Yelpers who have been on Yelp for longer are slightly more negative. There is also signifcant clustering within reviews of the same business as evidenced in the ICC.

Together, these findings suggest that when reading a restaurant review, one should think considerably about who is writing the review, as their general outlook may greatly contribute to their review.  Furthermore, one should expect that individual ratings of the same restaurant should be close to one another on average. 

### Limitations
Our study has a multitude of limitations. First we have introduced sampling error even within the Yelp dataset by taking a randome subsample of 10,000. Furthermore, we are unable to do model checking in a systematically robust fashion for the multi-level ordinal regression. In retrospect, I could have also selected more or better predictor variables from the JSON files.

Finally, if we are trying to generalize Yelp reviews to general restaurant experience, we introduce a host of additional limitation including that Yelp! reviews are not a random sample of all restaurant experiences.  Rather, users who have particularly interesting, positive, or negative experiences may be more likely to take the effort to write a review.  In addition, people who are very busy, concerned about online privacy, or generally do not spend much time online are unlikely to write Yelp! reviews, causing our sample to be unrepresentative. T

### Future Directions
Future work could look at more factors related to restaurant experiences, including restaurant cuisine and location, as well as reviewer gender and age. In addition, future software developers and statisticians may also devise more standardized methodologies for examining residuals and adapting similar diagnostic functionality for the class of multi-level ordinal functions as exist for the single level ones. 

## Reference
Dataset from twelfth annual Yelp Academic Challenge: https://www.yelp.com/dataset

(1) "Google, Yelp, Facebook Most Trusted For Online Reviews." 2018. 08/29/2013. Accessed December 9. https://www.mediapost.com/publications/article/328678/google-yelp-facebook-most-trusted-for-online-rev.html.

(2) Luca, Michael. "Reviews, Reputation, and Revenue: The Case of Yelp.com." Harvard Business School Working Paper, No. 12-016, September 2011. (Revised March 2016. Revise and resubmit at the American Economic Journal - Applied Economics.)

(3) Mahaney, Mark. Yelp Inc.: Gaining Speed in the Local Lane. Yelp Inc.: Gaining Speed in the Local Lane. New York, NY: RBC Capital Markets.

(4) Greenwell, Brandon, Andrew McCarthy, Bradley Boehmke, and Dungang Liu. 2018. "Residuals and Diagnostics for Binary and Ordinal Regression Models: An Introduction to the Sure Package." The R Journal 10 (1): 381-394. https://journal.r-project.org/archive/2018/RJ-2018-004/RJ-2018-004.pdf.

(5) C. Li and B. E. Shepherd. A new residual for ordinal outcomes. Biometrika, 99(2):473-480, 2012. URL
http://dx.doi.org/10.1093/biomet/asr073. [p382]

(6) D. Liu and H. Zhang. Residuals and diagnostics for ordinal regression models: A surrogate approach.
Journal of the American Statistical Association, URL http://dx.doi.org/10.1080/

(7) Christensen, Rune HB. Regression Models for Ordinal Data Introducing R-Package Ordinal.

## Appendix
#### Word count vs. stars
Very positive reviews tend to be much shorter than negative reviews.
```{r, include=F}
plot_data <- df %>%
 group_by(stars) %>%
 summarise(
   mean_word_count=mean(word_count),
   median_word_count=median(word_count),
   review_count=n()
 )
plot_data <- data.frame(plot_data)
plot_data <- reshape(
  plot_data,
  idvar="stars",
  varying=c("mean_word_count", "median_word_count"),
  v.names="word_count",
  direction="long",
  times=c("mean", "median")
)

plot12 <- ggplot(
   plot_data,
   aes(
     x=stars,
     y=word_count,
     color=time
   )
 ) +
   geom_point() +
   xlab("Review Stars") +
   ylab("Word Count") +
   ggtitle("Review Word Count by Stars") +
   theme_classic() +
   theme(plot.title=element_text(hjust=0.5)) +
  scale_color_brewer(
    name="Type",
    palette="Set2",
    labels=c("Mean", "Median")
  )
```

```{r, echo=FALSE}
plot12
```


### Restaurant review count
WThe following plot shows the relationship between average review ratings (1-5) and the number of reviews written about the restaurant. The blue line is a local regression fit to the points and shows that there is no strong relationship between review count and stars.  For this reason we do not include this variable in the regression analyses.
```{r, echo=FALSE}
plot13 <- ggplot(
  business_df,
  aes(
    x=mean_stars,
    y=review_count)) +
  geom_point() +
  scale_y_log10() +
  geom_smooth(method="loess", se=F) +
  xlab("Mean review stars") +
  ylab("Number of reviews") +
  ggtitle("Restaurant review volume by mean stars") +
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5))

plot13

```


### Linear regression
This model suggests that, holding constant the cost of the restaurant, people tend give higher ratings when the restaurant does not have a TV, and particularly when the business is not in the second price category.  This makes sense, as such restaurants would likely have lower quality food, and perhaps more frequently have cleanliness and service issues, two common themes in negative reviews.

In addition, this model suggests that the strongest predictor of having a positive restaurant experience is to usually have a positive experience.  This may be because certain people are generally more positive than others, or because certain people tend to go to better restaurants and therefore be able to write more positive reviews.

```{r, include=F}
plot14 <- coefplot(model4) +
  xlab('Coefficient predicting stars') +
  ylab('Independent variable') +
  ggtitle('Linear Regression Coefficients') +
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5))
```


```{r, echo=FALSE}
screenreg(model4, custom.model.names = "Single Level Linear Regression Model")
kable(round(confint(model4),2))
plot14
```

```{r, echo=FALSE}
binnedplot(fitted(model4), residuals(model4, type="response"))
```

```{r, include=F}
predicted <- predict(model4)
```

```{r, echo=FALSE}
hist(predicted)
```

```{r, echo=FALSE}
hist(df$stars)
```

### Multilevel linear regression
I fit a multilevel linear regression model with an intercept that varies across businesses.  This model allows us to account for clustering at the business level while still being able to estimate the effect of business-level factors.

I find very similar relationships with this model as with the previous ones.  The most predictive factor remains a user's previous review satisfaction, and restaurants with TVs and restaurants open 24-hours tend to have more negative reviews.
```{r, echo=FALSE}
screenreg(model5, custom.model.names = "Multi-Level Linear Regression Model")
kable(round(confint(model5),2))
plot15 <- coefplot(model5) +
  xlab('Coefficient predicting stars') +
  ylab('Independent variable') +
  ggtitle('Multi-Level Linear Regression Coefficients') +
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5))

plot15
```

```{r, echo=FALSE}
binnedplot(fitted(model5), residuals(model5, type="response"))
```
